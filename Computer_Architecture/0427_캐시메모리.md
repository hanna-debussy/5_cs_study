[toc]

# 캐시 메모리(Cache Memory)

## 캐시 메모리란?

* 캐시(Cache): 데이터나 값을 미리 복사해 놓는 임시 장소

  > 인터넷 브라우저에서 캐시 파일이라는 용어를 볼 수 있는데, 웹 페이지 상의 이미지 등을 하드디스크에 미리 저장해 두고 다음 접근 시 해당 사이트가 아닌 하드디스크에서 불러들여 로딩 속도를 높인다!

* 캐시 메모리(Cache Memory): 속도가 빠른 장치와 느린 장치 사이에서 속도 차에 따른 병목현상을 줄이기 위해 사용하는 메모리. 

  * CPU 캐시에서는... 메모리(CPU에 비해 저속)와 CPU 코어(고속) 사이 속도 차이를 완화하기 위해 메모리 데이터를 미리 가져와 저장해두는 임시 저장소

  * 속도를 향상시킨다는 장점을 얻지만, SRAM이기 때문에 비용이 매우 비싸서 용량이 적다는 특징이 있다.

    > SRAM(Static Random Access Memory, 정적 램)
    > 플립플롭 방식의 메모리 셀을 가지고 있어 DRAM과 다르게 Refresh를 계속 해줄 필요가 없다. 즉, 전원이 공급되는 한 기록된 데이터는 지워지지 않는다.
    > 하지만, 회로가 비교적 복잡하여 집적도가 낮고 가격이 비싸다는 단점이 있다.

  * 최신 프로세서는 캐시 메모리의 크기를 늘리고 속도를 줄이기 위해 L1, L2, L3의 세 세그먼트로 캐시를 구성하고 있다.

    * <img src="https://img2.quasarzone.com/editor/2021/01/16/c697dbaa10862212eba282c41d0e866c.png">

      > 듀얼 코어 프로세서의 캐시 메모리: 속도와 크기에 따라 L1, L2, L3 캐시 메모리로 분류되고, 이 순서대로 접근되어 데이터를 찾게 된다. 



### 캐시 메모리 작동

<img src="제목 없음.assets/image-20220427002138859.png" alt="image-20220427002138859" style="zoom: 80%;" />

> 캐시는 CPU 내부에 위치해서 CPU 내부 버스 속도로 작동 => 고속
>
> 메모리는 시스템 버스 속도로 작동 => 저속

* 프로세서가 메인 메모리를 읽거나 쓰고자 할 때는, 먼저 그 주소에 해당하는 데이터가 캐시에 존재하는지를 살핀다. 만약 그 주소의 데이터가 캐시에 있으면 데이터를 캐시에서 직접 읽고, 그렇지 않으면 메인 메모리에 직접 접근한다. 



* 캐시는 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종, CPU가 앞으로 사용할 데이터를 예상하고 미리 가져온다 == **`Prefetch`**

* CPU는 메모리에 접근하기 전, 캐시를 먼저 방문해 원하는 데이터를 찾는다.
  * 원하는 데이터가 존재한다 == **`캐시 히트(Cache Hit)`** -> 바로 사용한다.
  * 원하는 데이터가 없다 == **`캐시 미스(Cache Miss)`** -> 메모리로 접근해 데이터를 찾는다.
  * `캐시 적중률(Cache Hit Ratio)`: 캐시가 히트되는 비율, 일반적인 컴퓨터는 약 90%



* 캐시 미스의 종류
  1. Cold miss: 해당 메모리 주소를 처음 불러서 나는 미스
  2. Conflict miss(주소 할당 문제): 캐시 메모리에 A와 B 데이터를 저장해야 하는데, 이 둘이 같은 캐시 메모리 주소에 할당되어서 나는 미스
  3. Capacity miss(공간 문제): 캐시 메모리 공간부족으로 나는 미스



## 캐시 메모리의 지역성(Locality)

* 프로세스가 집중적으로 사용하는 페이지를 알아내는 방법 중 하나로, 캐시 메모리 시스템의 이론적 근거이다. 
  * 만약 프로세스가 모든 데이터를 균등하게 접근하거나 비슷한 시간에 참조한다면 캐시 효율이 떨어지게 된다. 그래서 접근하는 특정 순간에 집중적으로 참조하는 특성인 지역성의 원리를 이용해 캐시 적중률을 향상시킨다.



### 1. 시간 지역성(Temporal Locality)

* 프로세스가 실행되면서 하나의 페이지를 일정 시간 동안 집중적으로 액세스하는 현상
* **즉, 한 번 참조한 데이터는 가까운 시간 내에 계속 참조할 가능성이 높음을 의미한다!**
  * ex) loop, stack, 집계 등에서 사용되는 변수 등



### 2. 공간 지역성(Spatial Locality)

* 프로세스가 실행되면서 일정 위치의 페이지를 집중적으로 액세스하는 현상
* **즉, 특정 데이터가 참조되면 그 근처의 데이터를 계속 참조할 가능성이 높음을 의미한다.**
  * ex) 배열순회, 순차적 코드의 실행 등



## 캐시 메모리의 매핑 방식

### 1. 캐시 직접 매핑(Directed Mapping)

* 메모리에서와 동일한 배열을 가지도록 캐시에 저장하는 방식, 메모리와 캐시를 똑같은 크기로 나누고 순서대로 매핑한다.

  * 장점: 간단한 방식이라 구현이 쉽고, 탐색이 쉽다.
  * 단점: 캐시 적중률(Hit ratio)이 낮다.

    > 참고: <a href="https://m.blog.naver.com/you_maybe/221730246096">캐시 직접 매핑 단점</a>

* <img src="제목 없음.assets/image-20220427012734467.png" alt="image-20220427012734467" style="zoom: 50%;" /> <img src="https://i.imgur.com/yWWe5We.png" style="zoom:50%;" >
* 메모리에서 캐시로 데이터를 저장할 때, 지역성(Locality) 때문에 특정 데이터와 그 인접한 데이터를 함께 캐시 메모리를 저장한다. 이  단위가 **블록**이다. 그리고 캐시는 메인 메모리의 몇번째 블록인지를 알려주는 **태그**도 함께 저장한다. 
  
* 메모리 주소의 마지막 부분(붉은 영역)이 블럭의 크기를 의미한다. 크기가 4 => 두자리를 사용해 표현. 이 부분은 <u>블럭의 몇 번째 데이터가 원하는 데이터인지를 보여주는 지표</u>가 된다. 
  
* 같은 라인에 위치하는 데이터는 파란색 영역에 의해 구별이 가능하다. 
  
* 캐시 메모리에서 원하는 데이터를 찾는 방법
  
  1. 캐시의 태그와 주소상의 태그가 동일한지 확인한 후, 같으면 붉은 영역을 통해 데이터를 읽는다.
  
  2. 만일 태그가 다르다면 메모리에서 데이터를 가지고 온다.



### 2. 캐시 연관 매핑(Fully Associative Mapping)

* 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식
  * 캐시 직접 매핑의 단점을 보완하기 위해 등장한 방법으로, 캐시에 저장된 데이터들은 메인 메모리의 순서와는 아무런 관련이 없다.
  * 장점: 저장할 때 간편하고, 적중률이 높다
  * 단점: 검색 시 캐시를 전부 뒤져서 태그가 같은 데이터를 찾아내야 한다. (모든 태그를 병렬검사 한다)
* <img src="제목 없음.assets/image-20220427013518607.png" alt="image-20220427013518607" style="zoom: 50%;" />



### 3. 캐시 집합-연관 매핑(Set Associative Mapping)

* 직접 매핑 + 연관 매핑 둘의 장점을 취해 만들어졌으며, 특정 행을 지정하고 그 행 안의 어떤 열이든 비어있을 때 저장하는 방식

  * 직접 매핑에 비해 검색 속도는 느리지만 저장이 빠르고
  * 연관 매핑에 비해 저장이 느린 대신 검색이 빠른 중간 형태이다.

* <img src="제목 없음.assets/image-20220427013718401.png" alt="image-20220427013718401" style="zoom:50%;" />

  * 각각의 라인들이 하나의 세트에 속해 있고, 세트 번호를 통해 영역을 탐색한다. 

    > 세트 안의 라인 수에 따라 n-way 연관 매핑이라고 한다.

  * 라인에 매핑을 할 때는 무작위로 위치하게 된다.







## 퀴즈!

1. 캐시메모리는 지역성이라는 원리를 이용해 그 효율을 높이고 있다. 어떤 지역성을 사용하는지, 그 의미와 함께 기술하시오
2. 캐시의 매핑 방법 중 직접매핑과 연관매핑의 장점을 착안해 고안한 매핑방법을 소개하시오



<details markdown="1"> 
   <summary>Reference</summary>
    <ul>
      <li>
		<a href=" https://kadamon.tistory.com/category/%EA%B8%B0%EC%88%A0%EB%A9%B4%EC%A0%91/ComputerStructure">블로그 출처1</a>
		</li>
	  <li>
	  	<a href="https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Computer%20Architecture/%EC%BA%90%EC%8B%9C%20%EB%A9%94%EB%AA%A8%EB%A6%AC(Cache%20Memory).md#%EC%BA%90%EC%8B%9C-%EB%A9%94%EB%AA%A8%EB%A6%ACcache-memory">깃헙 출처1</a>
	  </li>
      <li>길벗알앤디, 시나공 기본서 정보처리기사 필기, 길벗, 2022</li> 
    </ul>
</details>